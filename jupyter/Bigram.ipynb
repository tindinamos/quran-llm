{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9339632c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('quran-simple.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10d8ee7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "735382"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06586528",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0123456789|ءآأؤإئابةتثجحخدذرزسشصضطظعغـفقكلمنهوىيًٌٍَُِّْٰۖۗۘۙۚۛۜ۩\n",
      "67\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "og_vocab = sorted(list(set(text)))\n",
    "print(''.join(og_vocab))\n",
    "print(len(og_vocab))\n",
    "std_vocab = '0123456789|ءآأؤإئابةتثجحخدذرزسشصضطظعغـفقكلمنهوىي ۩'\n",
    "std_vocab_size = len(std_vocab)\n",
    "print(std_vocab_size)\n",
    "\n",
    "reveries_vocab = 'ًٌٍَُِّْ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93f4bfe6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1|1|بِسْمِ اللَّهِ الرَّحْمَـٰنِ الرَّحِيمِ\\n1|2|الْحَمْدُ لِلَّهِ رَبِّ الْعَالَمِينَ\\n1|3|الرَّحْمَـ'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8163bf72-b68c-43da-870e-44caba82492a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def NextToken(index, text):\n",
    "    if text[index] in numerics:\n",
    "        token = [text[index],]\n",
    "        j = index + 1\n",
    "        while j < len(text) and text[j] in numerics:\n",
    "            token.append(text[j])\n",
    "            j += 1\n",
    "            if text[j-1] == '|':\n",
    "                break\n",
    "        return ''.join(token), j\n",
    "    elif text[index] in std_vocab:\n",
    "        token = [text[index],]\n",
    "        j = index + 1\n",
    "        while j < len(text) and text[j] in reveries_vocab:\n",
    "            token.append(text[j])\n",
    "            j += 1\n",
    "        return ''.join(token), j\n",
    "    else:\n",
    "        return text[index], index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c09bb25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436583\n"
     ]
    }
   ],
   "source": [
    "total = []\n",
    "numerics = '0123456789|'\n",
    "i = 0\n",
    "test_text = text # text[:1000000]\n",
    "while i < len(test_text):\n",
    "    token, i = NextToken(i, test_text)\n",
    "    # print(token)\n",
    "    total.append(token)\n",
    "print(len(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66bbad73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(654,\n",
       " ['\\n',\n",
       "  ' ',\n",
       "  '100|',\n",
       "  '101|',\n",
       "  '102|',\n",
       "  '103|',\n",
       "  '104|',\n",
       "  '105|',\n",
       "  '106|',\n",
       "  '107|',\n",
       "  '108|',\n",
       "  '109|',\n",
       "  '10|',\n",
       "  '110|',\n",
       "  '111|',\n",
       "  '112|',\n",
       "  '113|',\n",
       "  '114|',\n",
       "  '115|',\n",
       "  '116|',\n",
       "  '117|',\n",
       "  '118|',\n",
       "  '119|',\n",
       "  '11|',\n",
       "  '120|',\n",
       "  '121|',\n",
       "  '122|',\n",
       "  '123|',\n",
       "  '124|',\n",
       "  '125|',\n",
       "  '126|',\n",
       "  '127|',\n",
       "  '128|',\n",
       "  '129|',\n",
       "  '12|',\n",
       "  '130|',\n",
       "  '131|',\n",
       "  '132|',\n",
       "  '133|',\n",
       "  '134|',\n",
       "  '135|',\n",
       "  '136|',\n",
       "  '137|',\n",
       "  '138|',\n",
       "  '139|',\n",
       "  '13|',\n",
       "  '140|',\n",
       "  '141|',\n",
       "  '142|',\n",
       "  '143|',\n",
       "  '144|',\n",
       "  '145|',\n",
       "  '146|',\n",
       "  '147|',\n",
       "  '148|',\n",
       "  '149|',\n",
       "  '14|',\n",
       "  '150|',\n",
       "  '151|',\n",
       "  '152|',\n",
       "  '153|',\n",
       "  '154|',\n",
       "  '155|',\n",
       "  '156|',\n",
       "  '157|',\n",
       "  '158|',\n",
       "  '159|',\n",
       "  '15|',\n",
       "  '160|',\n",
       "  '161|',\n",
       "  '162|',\n",
       "  '163|',\n",
       "  '164|',\n",
       "  '165|',\n",
       "  '166|',\n",
       "  '167|',\n",
       "  '168|',\n",
       "  '169|',\n",
       "  '16|',\n",
       "  '170|',\n",
       "  '171|',\n",
       "  '172|',\n",
       "  '173|',\n",
       "  '174|',\n",
       "  '175|',\n",
       "  '176|',\n",
       "  '177|',\n",
       "  '178|',\n",
       "  '179|',\n",
       "  '17|',\n",
       "  '180|',\n",
       "  '181|',\n",
       "  '182|',\n",
       "  '183|',\n",
       "  '184|',\n",
       "  '185|',\n",
       "  '186|',\n",
       "  '187|',\n",
       "  '188|',\n",
       "  '189|',\n",
       "  '18|',\n",
       "  '190|',\n",
       "  '191|',\n",
       "  '192|',\n",
       "  '193|',\n",
       "  '194|',\n",
       "  '195|',\n",
       "  '196|',\n",
       "  '197|',\n",
       "  '198|',\n",
       "  '199|',\n",
       "  '19|',\n",
       "  '1|',\n",
       "  '200|',\n",
       "  '201|',\n",
       "  '202|',\n",
       "  '203|',\n",
       "  '204|',\n",
       "  '205|',\n",
       "  '206|',\n",
       "  '207|',\n",
       "  '208|',\n",
       "  '209|',\n",
       "  '20|',\n",
       "  '210|',\n",
       "  '211|',\n",
       "  '212|',\n",
       "  '213|',\n",
       "  '214|',\n",
       "  '215|',\n",
       "  '216|',\n",
       "  '217|',\n",
       "  '218|',\n",
       "  '219|',\n",
       "  '21|',\n",
       "  '220|',\n",
       "  '221|',\n",
       "  '222|',\n",
       "  '223|',\n",
       "  '224|',\n",
       "  '225|',\n",
       "  '226|',\n",
       "  '227|',\n",
       "  '228|',\n",
       "  '229|',\n",
       "  '22|',\n",
       "  '230|',\n",
       "  '231|',\n",
       "  '232|',\n",
       "  '233|',\n",
       "  '234|',\n",
       "  '235|',\n",
       "  '236|',\n",
       "  '237|',\n",
       "  '238|',\n",
       "  '239|',\n",
       "  '23|',\n",
       "  '240|',\n",
       "  '241|',\n",
       "  '242|',\n",
       "  '243|',\n",
       "  '244|',\n",
       "  '245|',\n",
       "  '246|',\n",
       "  '247|',\n",
       "  '248|',\n",
       "  '249|',\n",
       "  '24|',\n",
       "  '250|',\n",
       "  '251|',\n",
       "  '252|',\n",
       "  '253|',\n",
       "  '254|',\n",
       "  '255|',\n",
       "  '256|',\n",
       "  '257|',\n",
       "  '258|',\n",
       "  '259|',\n",
       "  '25|',\n",
       "  '260|',\n",
       "  '261|',\n",
       "  '262|',\n",
       "  '263|',\n",
       "  '264|',\n",
       "  '265|',\n",
       "  '266|',\n",
       "  '267|',\n",
       "  '268|',\n",
       "  '269|',\n",
       "  '26|',\n",
       "  '270|',\n",
       "  '271|',\n",
       "  '272|',\n",
       "  '273|',\n",
       "  '274|',\n",
       "  '275|',\n",
       "  '276|',\n",
       "  '277|',\n",
       "  '278|',\n",
       "  '279|',\n",
       "  '27|',\n",
       "  '280|',\n",
       "  '281|',\n",
       "  '282|',\n",
       "  '283|',\n",
       "  '284|',\n",
       "  '285|',\n",
       "  '286|',\n",
       "  '28|',\n",
       "  '29|',\n",
       "  '2|',\n",
       "  '30|',\n",
       "  '31|',\n",
       "  '32|',\n",
       "  '33|',\n",
       "  '34|',\n",
       "  '35|',\n",
       "  '36|',\n",
       "  '37|',\n",
       "  '38|',\n",
       "  '39|',\n",
       "  '3|',\n",
       "  '40|',\n",
       "  '41|',\n",
       "  '42|',\n",
       "  '43|',\n",
       "  '44|',\n",
       "  '45|',\n",
       "  '46|',\n",
       "  '47|',\n",
       "  '48|',\n",
       "  '49|',\n",
       "  '4|',\n",
       "  '50|',\n",
       "  '51|',\n",
       "  '52|',\n",
       "  '53|',\n",
       "  '54|',\n",
       "  '55|',\n",
       "  '56|',\n",
       "  '57|',\n",
       "  '58|',\n",
       "  '59|',\n",
       "  '5|',\n",
       "  '60|',\n",
       "  '61|',\n",
       "  '62|',\n",
       "  '63|',\n",
       "  '64|',\n",
       "  '65|',\n",
       "  '66|',\n",
       "  '67|',\n",
       "  '68|',\n",
       "  '69|',\n",
       "  '6|',\n",
       "  '70|',\n",
       "  '71|',\n",
       "  '72|',\n",
       "  '73|',\n",
       "  '74|',\n",
       "  '75|',\n",
       "  '76|',\n",
       "  '77|',\n",
       "  '78|',\n",
       "  '79|',\n",
       "  '7|',\n",
       "  '80|',\n",
       "  '81|',\n",
       "  '82|',\n",
       "  '83|',\n",
       "  '84|',\n",
       "  '85|',\n",
       "  '86|',\n",
       "  '87|',\n",
       "  '88|',\n",
       "  '89|',\n",
       "  '8|',\n",
       "  '90|',\n",
       "  '91|',\n",
       "  '92|',\n",
       "  '93|',\n",
       "  '94|',\n",
       "  '95|',\n",
       "  '96|',\n",
       "  '97|',\n",
       "  '98|',\n",
       "  '99|',\n",
       "  '9|',\n",
       "  'ءً',\n",
       "  'ءٌ',\n",
       "  'ءٍ',\n",
       "  'ءَ',\n",
       "  'ءُ',\n",
       "  'ءِ',\n",
       "  'آ',\n",
       "  'أً',\n",
       "  'أٌ',\n",
       "  'أَ',\n",
       "  'أُ',\n",
       "  'أْ',\n",
       "  'ؤً',\n",
       "  'ؤٌ',\n",
       "  'ؤَ',\n",
       "  'ؤُ',\n",
       "  'ؤِ',\n",
       "  'ؤْ',\n",
       "  'إٍ',\n",
       "  'إِ',\n",
       "  'ئً',\n",
       "  'ئٍ',\n",
       "  'ئَ',\n",
       "  'ئُ',\n",
       "  'ئِ',\n",
       "  'ئْ',\n",
       "  'ا',\n",
       "  'ب',\n",
       "  'بً',\n",
       "  'بٌ',\n",
       "  'بٍ',\n",
       "  'بَ',\n",
       "  'بُ',\n",
       "  'بِ',\n",
       "  'بًّ',\n",
       "  'بٌّ',\n",
       "  'بٍّ',\n",
       "  'بَّ',\n",
       "  'بُّ',\n",
       "  'بِّ',\n",
       "  'بْ',\n",
       "  'ةً',\n",
       "  'ةٌ',\n",
       "  'ةٍ',\n",
       "  'ةَ',\n",
       "  'ةُ',\n",
       "  'ةِ',\n",
       "  'ت',\n",
       "  'تً',\n",
       "  'تٌ',\n",
       "  'تٍ',\n",
       "  'تَ',\n",
       "  'تُ',\n",
       "  'تِ',\n",
       "  'تَّ',\n",
       "  'تُّ',\n",
       "  'تِّ',\n",
       "  'تْ',\n",
       "  'ث',\n",
       "  'ثً',\n",
       "  'ثٌ',\n",
       "  'ثٍ',\n",
       "  'ثَ',\n",
       "  'ثُ',\n",
       "  'ثِ',\n",
       "  'ثًّ',\n",
       "  'ثَّ',\n",
       "  'ثُّ',\n",
       "  'ثِّ',\n",
       "  'ثْ',\n",
       "  'جً',\n",
       "  'جٌ',\n",
       "  'جٍ',\n",
       "  'جَ',\n",
       "  'جُ',\n",
       "  'جِ',\n",
       "  'جًّ',\n",
       "  'جٍّ',\n",
       "  'جَّ',\n",
       "  'جُّ',\n",
       "  'جِّ',\n",
       "  'جْ',\n",
       "  'ح',\n",
       "  'حً',\n",
       "  'حٌ',\n",
       "  'حٍ',\n",
       "  'حَ',\n",
       "  'حُ',\n",
       "  'حِ',\n",
       "  'حَّ',\n",
       "  'حِّ',\n",
       "  'حْ',\n",
       "  'خً',\n",
       "  'خٌ',\n",
       "  'خٍ',\n",
       "  'خَ',\n",
       "  'خُ',\n",
       "  'خِ',\n",
       "  'خَّ',\n",
       "  'خِّ',\n",
       "  'خْ',\n",
       "  'د',\n",
       "  'دً',\n",
       "  'دٌ',\n",
       "  'دٍ',\n",
       "  'دَ',\n",
       "  'دُ',\n",
       "  'دِ',\n",
       "  'دًّ',\n",
       "  'دٌّ',\n",
       "  'دٍّ',\n",
       "  'دَّ',\n",
       "  'دُّ',\n",
       "  'دِّ',\n",
       "  'دْ',\n",
       "  'ذ',\n",
       "  'ذً',\n",
       "  'ذٌ',\n",
       "  'ذٍ',\n",
       "  'ذَ',\n",
       "  'ذُ',\n",
       "  'ذِ',\n",
       "  'ذَّ',\n",
       "  'ذُّ',\n",
       "  'ذِّ',\n",
       "  'ذْ',\n",
       "  'ر',\n",
       "  'رً',\n",
       "  'رٌ',\n",
       "  'رٍ',\n",
       "  'رَ',\n",
       "  'رُ',\n",
       "  'رِ',\n",
       "  'رًّ',\n",
       "  'رٌّ',\n",
       "  'رٍّ',\n",
       "  'رَّ',\n",
       "  'رُّ',\n",
       "  'رِّ',\n",
       "  'رْ',\n",
       "  'زً',\n",
       "  'زٌ',\n",
       "  'زٍ',\n",
       "  'زَ',\n",
       "  'زُ',\n",
       "  'زِ',\n",
       "  'زًّ',\n",
       "  'زَّ',\n",
       "  'زُّ',\n",
       "  'زِّ',\n",
       "  'زْ',\n",
       "  'س',\n",
       "  'سً',\n",
       "  'سٌ',\n",
       "  'سٍ',\n",
       "  'سَ',\n",
       "  'سُ',\n",
       "  'سِ',\n",
       "  'سًّ',\n",
       "  'سَّ',\n",
       "  'سُّ',\n",
       "  'سِّ',\n",
       "  'سْ',\n",
       "  'شً',\n",
       "  'شٌ',\n",
       "  'شٍ',\n",
       "  'شَ',\n",
       "  'شُ',\n",
       "  'شِ',\n",
       "  'شَّ',\n",
       "  'شُّ',\n",
       "  'شِّ',\n",
       "  'شْ',\n",
       "  'ص',\n",
       "  'صً',\n",
       "  'صٌ',\n",
       "  'صٍ',\n",
       "  'صَ',\n",
       "  'صُ',\n",
       "  'صِ',\n",
       "  'صَّ',\n",
       "  'صُّ',\n",
       "  'صِّ',\n",
       "  'صْ',\n",
       "  'ضً',\n",
       "  'ضٌ',\n",
       "  'ضٍ',\n",
       "  'ضَ',\n",
       "  'ضُ',\n",
       "  'ضِ',\n",
       "  'ضَّ',\n",
       "  'ضُّ',\n",
       "  'ضِّ',\n",
       "  'ضْ',\n",
       "  'ط',\n",
       "  'طً',\n",
       "  'طٌ',\n",
       "  'طٍ',\n",
       "  'طَ',\n",
       "  'طُ',\n",
       "  'طِ',\n",
       "  'طَّ',\n",
       "  'طُّ',\n",
       "  'طِّ',\n",
       "  'طْ',\n",
       "  'ظً',\n",
       "  'ظٌ',\n",
       "  'ظٍ',\n",
       "  'ظَ',\n",
       "  'ظُ',\n",
       "  'ظِ',\n",
       "  'ظًّ',\n",
       "  'ظٍّ',\n",
       "  'ظَّ',\n",
       "  'ظُّ',\n",
       "  'ظِّ',\n",
       "  'ظْ',\n",
       "  'ع',\n",
       "  'عً',\n",
       "  'عٌ',\n",
       "  'عٍ',\n",
       "  'عَ',\n",
       "  'عُ',\n",
       "  'عِ',\n",
       "  'عًّ',\n",
       "  'عَّ',\n",
       "  'عُّ',\n",
       "  'عِّ',\n",
       "  'عْ',\n",
       "  'غً',\n",
       "  'غٌ',\n",
       "  'غٍ',\n",
       "  'غَ',\n",
       "  'غُ',\n",
       "  'غِ',\n",
       "  'غْ',\n",
       "  'ـ',\n",
       "  'ف',\n",
       "  'فً',\n",
       "  'فٌ',\n",
       "  'فٍ',\n",
       "  'فَ',\n",
       "  'فُ',\n",
       "  'فِ',\n",
       "  'فًّ',\n",
       "  'فٍّ',\n",
       "  'فَّ',\n",
       "  'فُّ',\n",
       "  'فِّ',\n",
       "  'فْ',\n",
       "  'ق',\n",
       "  'قً',\n",
       "  'قٌ',\n",
       "  'قٍ',\n",
       "  'قَ',\n",
       "  'قُ',\n",
       "  'قِ',\n",
       "  'قًّ',\n",
       "  'قٌّ',\n",
       "  'قٍّ',\n",
       "  'قَّ',\n",
       "  'قُّ',\n",
       "  'قِّ',\n",
       "  'قْ',\n",
       "  'ك',\n",
       "  'كً',\n",
       "  'كٌ',\n",
       "  'كٍ',\n",
       "  'كَ',\n",
       "  'كُ',\n",
       "  'كِ',\n",
       "  'كًّ',\n",
       "  'كٌّ',\n",
       "  'كٍّ',\n",
       "  'كَّ',\n",
       "  'كُّ',\n",
       "  'كِّ',\n",
       "  'كْ',\n",
       "  'ل',\n",
       "  'لً',\n",
       "  'لٌ',\n",
       "  'لٍ',\n",
       "  'لَ',\n",
       "  'لُ',\n",
       "  'لِ',\n",
       "  'لًّ',\n",
       "  'لٌّ',\n",
       "  'لٍّ',\n",
       "  'لَّ',\n",
       "  'لُّ',\n",
       "  'لِّ',\n",
       "  'لْ',\n",
       "  'م',\n",
       "  'مً',\n",
       "  'مٌ',\n",
       "  'مٍ',\n",
       "  'مَ',\n",
       "  'مُ',\n",
       "  'مِ',\n",
       "  'مًّ',\n",
       "  'مٌّ',\n",
       "  'مٍّ',\n",
       "  'مَّ',\n",
       "  'مُّ',\n",
       "  'مِّ',\n",
       "  'مْ',\n",
       "  'ن',\n",
       "  'نً',\n",
       "  'نٌ',\n",
       "  'نٍ',\n",
       "  'نَ',\n",
       "  'نُ',\n",
       "  'نِ',\n",
       "  'نًّ',\n",
       "  'نٌّ',\n",
       "  'نَّ',\n",
       "  'نُّ',\n",
       "  'نِّ',\n",
       "  'نْ',\n",
       "  'ه',\n",
       "  'هً',\n",
       "  'هٌ',\n",
       "  'هٍ',\n",
       "  'هَ',\n",
       "  'هُ',\n",
       "  'هِ',\n",
       "  'هَّ',\n",
       "  'هُّ',\n",
       "  'هِّ',\n",
       "  'هْ',\n",
       "  'و',\n",
       "  'وً',\n",
       "  'وٌ',\n",
       "  'وَ',\n",
       "  'وُ',\n",
       "  'وِ',\n",
       "  'وًّ',\n",
       "  'وٌّ',\n",
       "  'وٍّ',\n",
       "  'وَّ',\n",
       "  'وُّ',\n",
       "  'وِّ',\n",
       "  'وْ',\n",
       "  'ى',\n",
       "  'ي',\n",
       "  'يً',\n",
       "  'يٌ',\n",
       "  'يَ',\n",
       "  'يُ',\n",
       "  'يِ',\n",
       "  'يًّ',\n",
       "  'يٌّ',\n",
       "  'يٍّ',\n",
       "  'يَّ',\n",
       "  'يُّ',\n",
       "  'يِّ',\n",
       "  'يْ',\n",
       "  'ٰ',\n",
       "  'ۖ',\n",
       "  'ۗ',\n",
       "  'ۘ',\n",
       "  'ۙ',\n",
       "  'ۚ',\n",
       "  'ۛ',\n",
       "  'ۜ',\n",
       "  '۩'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_vocab = sorted(list(set(total)))\n",
    "actual_vocab_size = len(actual_vocab)\n",
    "actual_vocab_size, actual_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef21b7dc-e0bc-4483-808b-0b669097c888",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('إِيَادْ إِبْرَاهِيمْ', 'إِيَادْ إِبْرَاهِيمْ')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi = {ch:i for i,ch in enumerate(actual_vocab)}\n",
    "itos = {i:ch for i,ch in enumerate(actual_vocab)}\n",
    "# encode = lambda s: [stoi[ss] for ss in s]\n",
    "def encode(text):\n",
    "    i = 0\n",
    "    total = []\n",
    "    while i < len(text): \n",
    "        token, i = NextToken(i, text)\n",
    "        total.append(stoi[token])\n",
    "    return total\n",
    "decode = lambda i: ''.join([itos[ii] for ii in i])\n",
    "\"إِيَادْ إِبْرَاهِيمْ\", decode(encode(\"إِيَادْ إِبْرَاهِيمْ\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "05e62c8b-08f5-4811-b084-68260931ba54",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ord() expected a character, but string of length 4 found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[142], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m text\u001b[38;5;241m.\u001b[39mtranslate({\u001b[38;5;28mord\u001b[39m(c): (c \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m actual_vocab \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m actual_vocab})[:\u001b[38;5;241m10\u001b[39m]\n",
      "Cell \u001b[0;32mIn[142], line 1\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m text\u001b[38;5;241m.\u001b[39mtranslate({\u001b[38;5;28mord\u001b[39m(c): (c \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m actual_vocab \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m actual_vocab})[:\u001b[38;5;241m10\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: ord() expected a character, but string of length 4 found"
     ]
    }
   ],
   "source": [
    "# text.translate({ord(c): (c if c in vocab else None) for c in vocab})[:10]\n",
    "# Not working for some reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47e0b1c8-7cc9-44ef-a04a-0b5003c52b1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([112, 112, 321, 450, 586,   1, 314, 566, 576, 613,   1, 314, 566, 424,\n",
      "        379, 584, 524, 645, 600,   1, 314, 566, 424, 376, 632, 586,   0, 112,\n",
      "        210, 314, 579, 374, 593, 394,   1, 572, 576, 613,   1, 418, 327,   1,\n",
      "        314, 579, 509, 314, 570, 586, 632, 598,   0, 112, 221, 314, 566, 424,\n",
      "        379, 584, 524, 645, 600,   1, 314, 566, 424, 376, 632, 586,   0, 112,\n",
      "        232, 584, 314, 572, 558,   1, 635, 630, 586,   1, 314, 566, 401, 632,\n",
      "        600,   0, 112, 243, 307, 641, 314, 556,   1, 598, 516, 320, 394,   1,\n",
      "        621, 307, 641, 314, 556,   1, 598, 450, 339, 511, 632, 599,   0, 112,\n",
      "        254, 314, 617, 395, 598, 314,   1, 314, 566, 470, 418, 314, 486,   1,\n",
      "        314, 579, 585, 450, 339, 544, 632, 584,   0, 112, 265, 467, 418, 314,\n",
      "        486,   1, 314, 576, 409, 632, 598,   1, 297, 606, 509, 593, 339,   1,\n",
      "        509, 570, 644, 613, 593,   1, 520, 644, 420,   1, 314, 579, 584, 523,\n",
      "        476, 618, 321,   1, 509, 570, 644, 613, 593,   1, 621, 570, 314,   1,\n",
      "        314, 566, 478, 314, 578, 632, 598,   0, 210, 112, 321, 450, 586,   1,\n",
      "        314, 566, 576, 613,   1, 314, 566, 424, 379, 584, 524, 645, 600,   1,\n",
      "        314, 566, 424, 376, 632, 586,   1, 314, 566, 580,   0, 210, 210, 407,\n",
      "        645, 572, 556,   1, 314, 579, 558, 339, 314, 320,   1, 570, 314,   1,\n",
      "        418, 644, 319,   1, 651,   1, 531, 632, 613,   1, 651,   1, 612, 390,\n",
      "        631,   1, 578, 579, 585, 342, 544, 632, 598,   0, 210, 221, 314, 576,\n",
      "        409, 632, 598,   1, 636, 305, 586, 599, 618, 598,   1, 321, 314, 579,\n",
      "        520, 644, 321,   1, 621, 636, 544, 632, 585, 618, 598,   1, 314, 566,\n",
      "        468, 570, 314, 332,   1, 621, 586, 590, 314,   1, 418, 431, 551, 598,\n",
      "        314, 612, 593,   1, 636, 594, 531, 543, 618, 598,   0, 210, 232, 621,\n",
      "        314, 576, 409, 632, 598,   1, 636, 305, 586, 599, 618, 598,   1, 321,\n",
      "        584, 314,   1, 298, 594, 433, 570,   1, 307, 570, 644, 556,   1, 621,\n",
      "        584, 314,   1, 298, 594, 433, 570,   1, 586, 594,   1, 542, 328, 572,\n",
      "        556,   1, 621, 321, 314, 579, 294, 385, 418, 334,   1, 612, 593,   1,\n",
      "        636, 618, 544, 599, 618, 598,   0, 210, 243, 298, 618, 570, 524, 645,\n",
      "        312, 556,   1, 509, 570, 631, 645,   1, 612, 390, 631,   1, 592, 594,\n",
      "          1, 424, 327, 613, 593,   1, 646,   1, 621, 298, 618, 570, 524, 645,\n",
      "        312, 556,   1, 612, 585,   1, 314, 579, 585, 537, 572, 375, 618, 598,\n",
      "          0, 210, 254, 307, 603,   1, 314, 576, 409, 632, 598,   1, 556, 529,\n",
      "        419, 618, 314,   1, 443, 621, 314, 289,   1, 509, 570, 644, 613, 593,\n",
      "          1, 297, 297, 594, 407, 427, 339, 612, 593,   1, 297, 593,   1, 570,\n",
      "        593,   1, 340, 594, 409, 427, 612, 593,   1, 570, 314,   1, 636, 305,\n",
      "        586, 599, 618, 598,   0, 210, 265, 383, 339, 584,   1, 314, 566, 576,\n",
      "        612,   1, 509, 570, 631, 645,   1, 543, 571, 618, 321, 613, 593,   1,\n",
      "        621, 509, 570, 631, 645,   1, 443, 593, 511, 613, 593,   1, 646,   1,\n",
      "        621, 509, 570, 631, 645,   1, 297, 328, 465, 314, 420, 613, 593,   1,\n",
      "        522, 454, 314, 621, 330,   1, 646,   1, 621, 570, 612, 593,   1, 509,\n",
      "        407, 314, 317,   1, 509, 498, 632, 582,   0, 210, 276, 621, 586, 598,\n",
      "          1, 314, 566, 603, 314, 445,   1, 584, 594,   1, 635, 543, 618, 571,\n",
      "          1, 294, 584, 603, 314,   1, 321, 314, 566, 576, 613,   1, 621, 321,\n",
      "        314, 579, 635, 630, 586,   1, 314, 579, 294, 385, 420,   1, 621, 584,\n",
      "        314,   1, 612, 580,   1, 321, 585, 305, 586, 600, 632, 598,   0, 210,\n",
      "        287, 636, 383, 314, 395, 510, 618, 598,   1, 314, 566, 576, 611,   1,\n",
      "        621, 314, 576, 409, 632, 598,   1, 294, 584, 599, 618, 314,   1, 621,\n",
      "        584, 314,   1, 635, 388, 393, 510, 618, 598,   1, 307, 576, 314,   1,\n",
      "        297, 594, 530, 443, 612, 593,   1, 621, 584, 314,   1, 635, 460, 510,\n",
      "        419, 618, 598,   0, 210,  12, 531, 632,   1, 543, 571, 618, 321, 613,\n",
      "        580,   1, 590, 418, 473,   1, 529, 431, 314, 393, 612, 585,   1, 314,\n",
      "        566, 576, 612,   1, 584, 418, 472, 314,   1, 646,   1, 621, 570, 612,\n",
      "        593,   1, 509, 407, 314, 317,   1, 297, 572, 632, 582,   1, 321, 584,\n",
      "        314,   1, 556, 314, 599, 618, 314,   1, 635, 565, 409, 320, 618, 598,\n",
      "          0, 210,  23, 621, 307, 407, 314,   1, 544, 632, 570,   1, 570, 612,\n",
      "        593,   1, 570, 314,   1, 340, 537, 445, 394, 618, 314,   1, 531, 632,\n",
      "          1, 314, 579, 297, 427, 477,   1, 542, 314, 571, 618, 314,   1, 307,\n",
      "        603, 584, 314,   1, 598, 379, 599,   1, 585, 471, 572, 375, 618, 598,\n",
      "          0, 210,  34, 297, 570, 314,   1, 307, 603, 612, 593,   1, 612, 585,\n",
      "          1, 314, 579, 585, 537, 445, 394, 618, 598,   1, 621, 570, 524, 645,\n",
      "        558, 594,   1, 576, 314,   1, 635, 460, 510, 419, 618, 598,   0, 210,\n",
      "         45, 621, 307, 407, 314,   1, 544, 632, 570,   1, 570, 612, 593,   1,\n",
      "        294, 586, 599, 618, 314,   1, 556, 584, 314,   1, 294, 584, 598,   1,\n",
      "        314, 566, 603, 314, 444,   1, 542, 314, 571, 618, 314,   1, 297, 599,\n",
      "        305, 586, 599,   1, 556, 584, 314,   1, 294, 584, 598,   1, 314, 566,\n",
      "        448, 529, 611, 314, 292,   1, 647,   1, 297, 570, 314,   1, 307, 603,\n",
      "        612, 593,   1, 612, 585,   1, 314, 566, 448, 529, 611, 314, 292,   1,\n",
      "        621, 570, 524, 645, 558, 594,   1, 576, 314,   1, 635, 516, 570, 585,\n",
      "        618, 598,   0, 210,  56, 621, 307, 407, 314,   1, 570, 543, 618, 314,\n",
      "          1, 314, 576, 409, 632, 598,   1, 294, 584, 599, 618, 314,   1, 542,\n",
      "        314, 571, 618, 314,   1, 294, 584, 603, 314,   1, 621, 307, 407, 314,\n",
      "          1, 383, 570, 630, 314,   1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.tensor(encode(text), dtype = torch.long)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b323c0b5-0168-483a-87e9-38c8383d5f21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = int(0.9 * len(data))\n",
    "# revisit this. Quran is complicated and end is probably the shorter verses which means training and validation are already diverting.\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6ef3c0d-51ed-4f7b-b003-eeb8e5ae185f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([112, 112, 321, 450, 586,   1, 314, 566, 576])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a101f8c-9688-4440-89f0-49fd859a390a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  tensor([112])  and target:  tensor(112)\n",
      "input:  tensor([112, 112])  and target:  tensor(321)\n",
      "input:  tensor([112, 112, 321])  and target:  tensor(450)\n",
      "input:  tensor([112, 112, 321, 450])  and target:  tensor(586)\n",
      "input:  tensor([112, 112, 321, 450, 586])  and target:  tensor(1)\n",
      "input:  tensor([112, 112, 321, 450, 586,   1])  and target:  tensor(314)\n",
      "input:  tensor([112, 112, 321, 450, 586,   1, 314])  and target:  tensor(566)\n",
      "input:  tensor([112, 112, 321, 450, 586,   1, 314, 566])  and target:  tensor(576)\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size + 1]\n",
    "x, y\n",
    "context = []\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    print('input: ', context, ' and target: ', y[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "062bbebb-c53c-45db-853c-76ae37eeb014",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[  1, 646,   1, 621, 314, 342, 543, 618],\n",
      "        [618, 598,   1, 529, 341, 632, 567, 314],\n",
      "        [585, 618, 443, 631, 645,   0, 123, 241],\n",
      "        [  1, 529, 570, 314,   1, 339, 413, 611]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[646,   1, 621, 314, 342, 543, 618, 314],\n",
      "        [598,   1, 529, 341, 632, 567, 314,   0],\n",
      "        [618, 443, 631, 645,   0, 123, 241, 529],\n",
      "        [529, 570, 314,   1, 339, 413, 611, 328]])\n",
      "----\n",
      "when input is [1] the target: 646\n",
      "when input is [1, 646] the target: 1\n",
      "when input is [1, 646, 1] the target: 621\n",
      "when input is [1, 646, 1, 621] the target: 314\n",
      "when input is [1, 646, 1, 621, 314] the target: 342\n",
      "when input is [1, 646, 1, 621, 314, 342] the target: 543\n",
      "when input is [1, 646, 1, 621, 314, 342, 543] the target: 618\n",
      "when input is [1, 646, 1, 621, 314, 342, 543, 618] the target: 314\n",
      "when input is [618] the target: 598\n",
      "when input is [618, 598] the target: 1\n",
      "when input is [618, 598, 1] the target: 529\n",
      "when input is [618, 598, 1, 529] the target: 341\n",
      "when input is [618, 598, 1, 529, 341] the target: 632\n",
      "when input is [618, 598, 1, 529, 341, 632] the target: 567\n",
      "when input is [618, 598, 1, 529, 341, 632, 567] the target: 314\n",
      "when input is [618, 598, 1, 529, 341, 632, 567, 314] the target: 0\n",
      "when input is [585] the target: 618\n",
      "when input is [585, 618] the target: 443\n",
      "when input is [585, 618, 443] the target: 631\n",
      "when input is [585, 618, 443, 631] the target: 645\n",
      "when input is [585, 618, 443, 631, 645] the target: 0\n",
      "when input is [585, 618, 443, 631, 645, 0] the target: 123\n",
      "when input is [585, 618, 443, 631, 645, 0, 123] the target: 241\n",
      "when input is [585, 618, 443, 631, 645, 0, 123, 241] the target: 529\n",
      "when input is [1] the target: 529\n",
      "when input is [1, 529] the target: 570\n",
      "when input is [1, 529, 570] the target: 314\n",
      "when input is [1, 529, 570, 314] the target: 1\n",
      "when input is [1, 529, 570, 314, 1] the target: 339\n",
      "when input is [1, 529, 570, 314, 1, 339] the target: 413\n",
      "when input is [1, 529, 570, 314, 1, 339, 413] the target: 611\n",
      "when input is [1, 529, 570, 314, 1, 339, 413, 611] the target: 328\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4 # how many independent sequences will we process in parallel?\n",
    "block_size = 8 # what is the maximum context length for predictions?\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('----')\n",
    "\n",
    "for b in range(batch_size): # batch dimension\n",
    "    for t in range(block_size): # time dimension\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03fa35ab-88fc-4d81-887e-5b933a6c2ca3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 654])\n",
      "tensor(7.0400, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "229|199|90|شٍصْمِّ101|صٌ274|عُّذًصٌاحً184|خَّبًئٍنَ6|بٌّدِعُلٍهٍ242|هٍ247|245|سٌطبُ236|ذْ145|1|زْ6|215|ثِ174|تًهسِّ140|187|هُ238|ذُرٌّذِكَّدٍّ238|79|127|بعً239|هجُّ12|110|ثَ194|حُأٌ165|12|سٌ196|يَّ246|142|صَّءِ42|دِّثِرِّفُّ97|229|144|56|207|كُ231|165|47|مُّبٍّذَثٌ116|سْ244|نٌّ258|مِسُ223|267|64|34|طٌنٍ24|231|\n",
      "ث83|ذْبَّقِّ254|خِ41|22|219|بِ260|12|ءٍكُّكٌّنًكَّتَمٍّطُّ102|68|طكٍّ89|101|ظُمٌءٌخٍ244|95|ذْقًّؤِ14|25|144|بٍ103|مُكٌّ220|فِ52|ةَةً15|ذٌشِسِشْ44|247|156|69|عُّةُعٍ274|مٌحٌ136|62|شَّجَّ74|عًبْجَسْكَّهْدتًفٌ69|ذٌغِط262|دْجٌ177|قٍّعًّجٍّلُّبُّلً210|196|87|266|74|حُ247|242|بٌ125|م200|ثًّلُّذِ182|91|9|عُ126|109|جَكُ224|ثًضِّ265|140|مُّذَّمِ143|عٍفْ173|رٌّ36|228|ءِ214|253|59|180|243|ۜصَّ252|مِ176|ؤٌثٌقَ242|223|حٍؤِثً221|229|دِّ181|241|46|جٍوُّ58|وًّنِّ182|214|255|189|يٌّتُّضُّزَ269|22|183|158|فُّ37|221|صٌةَ70|31|قً139|142|276|41|كُّأْ123|96|17|182|\n",
      "89|أُخْطَّأٌضَّوِ235|5|خُشِّذُ222|111|رمٍّ143|86|تُصًتًضَ40|212|44|198|أٌمًزُّ235|161|هَ15|30|أُ38|7|مِّ4|5|بِ120|149|طِسظْخَّ3|خٌضِ259|37|213|188|268|ئُ82|تُّ269|263|صهُ90|211|سًقٍ258|فَبٌظًثِّت146|زِنَ248|تُئَةًوٍّيًّ152|ظًّزَّمْفْؤٌسَّ25|107|185|دِّو240|طْ173|شٌ199|162|قٌ35|زًوَ108|32|255|10|ةٍ248|خَّ49|16|مِيكُن229|67|عِّادٍقٌ80|20|ظَّفْسٍ36|يُ245|قٍيْ241|2|235|53|132|71|51|234|179|139|233|قٌّ235|ت 179|عَ230|283|68|115|لٍّأٌعًّمَذتب212|280|264|5|242|صَّغُ45|43|244|لِّصُّءٌ275|214|قٌّذَ226|كُّئَ188|164|رِّ265|22|ضٍ279|دِّفًصٌمًّرُيِّذُذًذِّذْ117|حٌذِ71|187|طْغًنًبةٌ87|129|ت204|100|فٍمًتِهِّعًّ132|ذْ222|طِسٌ1|رٍدِّشُ163|176|101|274|صحً108|ۖ33|خَ182|نلُ110|227|218|279|سُيِ251|رٌّ127|ئْثِ137|ثًصُةُصِفُّفٌعَخٍلِّ54|جُّ10|250|137|سْعَيَ126|ضً156|ۚؤْزَ254|بُ\n",
      "عً233|189|زُ148|96|115|234|نٍكَّظَ236|76|دِصُأَدٌذًهٍرًّ244|شٌ45|نْ100|174|صِّذًثِذَّ195|9|ؤُ249|142|93|مٍّ152|يُمِلْةًهفْ21|دِ83|218|فِ96|175|251|152|20|كُّسُزًّأَذَّ278|20|سًغْ282|جَّشٌ168|246|لِوٍّ188|ذْكٍحدُّ120|ظَّۛسُّ85|قَّ80|225|طُّدًخِ119|لُّكُّحَّفَرَرٍّبُۘعَّ157|قٌ123|157|ءَ91|157|هِّبَّفُ183|59|194|ضَّ239|ثُ63|210|104|زًزُمًّ171|155|ةٌقً237|هُ231|قُصُسِنُّ286|95|لٍّ269|رجُبِّزٍئِ62|شًفِطً82|225|عً54|253|أْعْ41|6|۩فٍخًسٌ104|212|رٍ263|ءٌ91|ذ33|143|96|140|221|235|يَ93|سْغِ46|دًنْيْائْحْذَظُّلِّفٌبٍ131|10|طْءِطُ169|168|ئِةَ217|وجُءِذَّشٌلُضُذَّلَّ206|61|قَ187|صٍ150|157|84|ظًّرَّ270|193|281|116|103|تِ117|279|ظًّشِ175|232|ۛبًوٌّخٍبٌ77|ذٌلسُّ100|وٌ42|96|خْ275|6|16|بٌذَّ141|ثٌعيُّ222|زِّحِكِّ205|تً179|صْسُّبيُّيُ10|زُ94|عْضِ121|224|241|۩119|240|115|فًّ99|146|هُّ213|ضِّر182|264|104|ظٍصٌدٌّ159|117|67|طَّ264|ن250|229|223|أْ219|254|72|طَّرٌّ30|أْنًجُظٍوٍّ141|كً277|قٍّؤَوَ275|أٌهَّ115|ؤٌخْظَّخٌس105|هٍ215|17|265|دِظِّ48|119|130|210|197|ذ222|ح221|24|شْ168|284|دٌدِّ256|45|144|266|صَّم177|251|208|بٌّ47|82|بِ24|غِ216|كِّ246|دَّ168|ثْشٌ96|مُبٍّسٍ136|وٌيٍّجًّ267|بٌّكُّ214|لًّ62|204|ظٍّ205|105|فٌدٌّ245|280|حٍوٌلً267|155|جٍّحًطِّ235|64|عِّ153|مًيٌ153|254|211|176|108|50|نٌّ40|ثً13|50|228|خُ247|فٍ49|و161|قَّ35|نِّغً\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.manual_seed(4337)\n",
    "\n",
    "class BigramLanguageModule(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        logits = self.token_embedding_table(idx)\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C) # I need to read on the cross_entropy function to understand why merging the B&T at the start removes the need\n",
    "            # for the T at the end.\n",
    "            loss = F.cross_entropy(logits, targets.view(B*T))\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "\n",
    "m = BigramLanguageModule(actual_vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "print(decode(m.generate(torch.zeros((1,1), dtype=torch.long), max_new_tokens=1000)[0].tolist()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2eb2277-f5be-4c4d-8004-0832040961c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "667928d5-116a-4144-bd40-2edbaeb61730",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5949740409851074\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(100000): # increase number of steps for good results...\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b8a3ddc-38b5-482f-8edf-14685a082485",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "36|4|75|وَالْبَاسِيَبْطِينَىٰكِتَثْلِي ا عَنَ رَّسُلُعِيكُلِّ سَلَئِمِندِيَالْأَتَيْهِنَّ عَذَانُونَ الشَّيْنَ\n",
      "40|أَضَهُمْ الرِّبَكَالَىٰ فَتَ بِهِ مِن مَادْ تَطِيهًالْأَيَقُوا عَوْنُؤْمِ أَرْدُونَ فَالْإِذَهُمْ ال عَلَعْرِ\n",
      "26|194|مَن ا أَقْتُم\n",
      "9|36|فَضْلِقَبْعَمِلُهُمْ لَا هِ لَ الطُّونَا ادٍ صنَاحِيدَ فِيكُرُكُونَنَاتَّقُوا وَالرُّسُبْلِمِ ۖ لَ ا\n",
      "41|37|140|ـٰ بِأَجِبَعُ مَ أَتَبِيهَ لَّهُ تَ كَارَنَّابِارِ ضَرَةِ ا أَ جُولِيهِ أَيْنَ يَكُمْ ثُمَّ تُثِيزٌ ا مِمَّ عَلْأَلِكُمْ يَدَنَّمَلَمِن عِيبٌ كِتَ إِلَّهَنَّاوَيُرِضُحًىٰكِرٍ\n",
      "44|48|9|125|وَالْحَسِنِينِيدَتَ ۖ عَلَةً ۚ ۚ مَنَّ الْعَنْيَسْتَعَذَٰ اللَّةَ بِوَالَـٰلِكَا إِنَّ إِلَاجَّ قَوْلَىٰذَا بَعْرِكُم وَنَّ دَ قَدِرُونَ وَلَ لَّهُ فَرُ قَ لَقَوْمُواكٌ الَّهِ اسْجُلٌ يَتَخَرَقْوِزْوَمَ عَلُوبَعْدَجَمْ بِا خَبِادَةً فَا يَتَّبِمَنظُنُّبُيُظْلَاللَّمَرَ ابَ ۚ الَعَشِدُعَةً رُوبِنَصِيمِنَذِي مَا قُلْمٍ تَجْهِ أُوسَنَ فِينٍضَلَّتِ سَيَوْمٍ إِلَّهِ إِيَّ عِي مُوءٍ مَنْهُ سَفَلَ لِيَا إِنَّ يُؤْمِنَ\n",
      "8|21|وَحَقُّوا إِلَّيْلِكُنزَنُذِيلَا اصِينَ عَلَ تَ تَأْذَا ۖ الْحُولُ وَإِلَّهَ تَأْكُمْلَقَدْعُ ا ا الَ جَا فُ مَّا اوَآللَّذِي إِنَّاةَ تُحْنُوا\n",
      "2|26|193|وَا ۖ تَدْ ا وَاجِدَقَ وَمَسَطُولُوالنُّوا مِّنذِهِمْ عَهُ إِنَّا شَالَىٰ إِنَّ خَذَاءَ بِأَن ا ۚ أُفٍّ187|دتُّمُوءٍ تَهُ وَتَا قُونَ هَاضَرَوُجُونَ غَيْءٍ أَشْتَانُ بِصِيَّ مِنَ لَّذِفُونِ لَّهُمُ لَ تَعْطَالْغَوِ ا حَتَّخَفَّةً هَاتِكَفَقَاللَّذِيبٍ اءُونَ\n",
      "53|وَشُوا ۖ يَمْرَسُواءُ تَعَوْمَا مِّنتَجِي وَاعِنسِلْبَىٰذِيهِ يَتَّقُلْ ۚ ذُرِّينَ قَةً ا أَوَجَّيْلَقْسِلْوَمَا آيَخْفَعُوا مُّؤْمِنزَلْنَ إِنَّ فَبِأَسْمَعَجِدَ إِلَقَاحِينَا ابِكُنتَلُونَالسَّمَاذْهِهِ تُمْلُونَ أَخَا لَا وَنَهُ مَنُوا خَلْمَنْ لِكَا الْحَا يَالَّهِمْ عَلَيْكُمْ أَرْسَهُ نَ إِمَا \n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(torch.zeros((1,1), dtype=torch.long), max_new_tokens=1000)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
